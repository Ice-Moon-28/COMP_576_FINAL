{"model": "meta-llama/Llama-2-7b-hf", "dataset": "coqa", "device": "mps", "fraction_of_data_to_use": 1.0, "num_generations_per_prompt": 10, "temperature": 0.5, "decoding_method": "greedy", "top_p": 0.99, "top_k": 10, "seed": 2023, "nprocess": null, "project_ind": 0, "batch_size": 1, "knock_out": false}